{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yellow-transition",
   "metadata": {},
   "source": [
    "# Algorithm 6:  Handling Conditional Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "multiple-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "interim-corruption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree',\n",
       "       'is_recid', 'is_violent_recid', 'type_of_assessment', 'decile_score.1',\n",
       "       'score_text', 'screening_date', 'v_type_of_assessment',\n",
       "       'v_decile_score', 'v_score_text', 'v_screening_date', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "df.columns[df.isna().any()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "valid-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['sex','age','race','priors_count','c_charge_degree','two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "laden-crazy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>African-American</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex  age              race  priors_count c_charge_degree  \\\n",
       "0       Male   34  African-American             0               F   \n",
       "1       Male   24  African-American             4               F   \n",
       "2       Male   23  African-American             1               F   \n",
       "3       Male   41         Caucasian            14               F   \n",
       "4     Female   39         Caucasian             0               M   \n",
       "...      ...  ...               ...           ...             ...   \n",
       "6145    Male   30  African-American             0               M   \n",
       "6146    Male   20  African-American             0               F   \n",
       "6147    Male   23  African-American             0               F   \n",
       "6148    Male   23  African-American             0               F   \n",
       "6149  Female   33  African-American             3               M   \n",
       "\n",
       "      two_year_recid  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  0  \n",
       "...              ...  \n",
       "6145               1  \n",
       "6146               0  \n",
       "6147               0  \n",
       "6148               0  \n",
       "6149               0  \n",
       "\n",
       "[6150 rows x 6 columns]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df[selected_features][(df['race']=='Caucasian') | (df['race']=='African-American')].copy()\n",
    "df_cleaned.head()\n",
    "df_cleaned.index = np.arange(0,len(df_cleaned))\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "grand-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dexpl(df,expl,out='two_year_recid'):\n",
    "    pdelta = []\n",
    "    pstar = []\n",
    "    for v in df[expl].unique():\n",
    "        pa = 0 if np.isnan((df[df['race']=='African-American'][expl] == v).mean()) else (df[df['race']=='African-American'][expl] == v).mean()\n",
    "        pc = 0 if np.isnan((df[df['race']=='Caucasian'][expl] == v).mean()) else (df[df['race']=='Caucasian'][expl] == v).mean()\n",
    "        pdelta.append(pa-pc) \n",
    "        psa = (df[(df['race']=='African-American') & (df[expl] == v)][out] == 1).mean()\n",
    "        psa = 0 if np.isnan(psa) else psa\n",
    "        psc = (df[(df['race']=='Caucasian') & (df[expl] == v)][out] == 1).mean()\n",
    "        psc = 0 if np.isnan(psc) else psc\n",
    "        pstar.append((psa+psc)/2)\n",
    "    return sum([pdelta[i]*ps for i,ps in enumerate(pstar)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "residential-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(df_i,race):\n",
    "    g_i = (df_i['race']==race).sum()\n",
    "    p_star_a = (df_i[df_i['race']=='African-American']['two_year_recid'] == 1).mean()\n",
    "    p_star_a = 0 if np.isnan(p_star_a) else p_star_a\n",
    "    p_star_c = (df_i[df_i['race']=='Caucasian']['two_year_recid'] == 1).mean()\n",
    "    p_star_c = 0 if np.isnan(p_star_c) else p_star_c\n",
    "    p_star = (p_star_a+p_star_c)/2\n",
    "    if race == 'African-American':\n",
    "        return g_i*abs(p_star_a-p_star)\n",
    "    if race == 'Caucasian':\n",
    "        return g_i*abs(p_star_c-p_star)\n",
    "    \n",
    "def LocalMassaging(df,expl,numerical=['priors_count']):\n",
    "    df_copy = df.copy()\n",
    "    for attr in np.unique(df[expl]):\n",
    "        X_df = df[df[expl]==attr]\n",
    "        X = OneHotEncoder(drop='if_binary',sparse=False).fit_transform(X_df.drop(['race','two_year_recid',expl]+numerical,axis=1))\n",
    "        \n",
    "        X = np.hstack((X,X_df[numerical].to_numpy()))\n",
    "        y = OneHotEncoder(drop='if_binary',sparse=False).fit_transform(df[df[expl]==attr][['two_year_recid']])\n",
    "        np.random.seed(0)\n",
    "        if not any(y):\n",
    "            y[np.random.randint(low=0,high=len(y))]=1\n",
    "        if all(y):\n",
    "            y[np.random.randint(low=0,high=len(y))]=0\n",
    "        if len(y) == 1:\n",
    "            continue\n",
    "        clf_logistic = LogisticRegression(random_state=0,max_iter=1000).fit(X, y.flatten())\n",
    "        y_prob  = clf_logistic.predict_log_proba(X) \n",
    "        \n",
    "        num_a = delta(X_df,'African-American')\n",
    "        num_c= delta(X_df,'Caucasian')\n",
    "        positive_index_sorted = np.argsort(y_prob[:,1])[np.sort(y_prob[:,1])>np.log(0.5)]\n",
    "        negative_index_sorted = np.argsort(y_prob[:,1])[np.sort(y_prob[:,1])<np.log(0.5)]\n",
    "        count_a,count_c = 0,0\n",
    "        \n",
    "        for index in positive_index_sorted:\n",
    "            if df_copy.at[X_df.index[index],'race']== 'African-American':\n",
    "                df_copy.at[X_df.index[index],'two_year_recid'] = 0\n",
    "                count_a += 1\n",
    "            if count_a >= num_a:\n",
    "                break\n",
    "        for index in reversed(negative_index_sorted):\n",
    "            if df_copy.at[X_df.index[index],'race']== 'Caucasian':\n",
    "                df_copy.at[X_df.index[index],'two_year_recid'] = 1\n",
    "                count_c += 1\n",
    "            if count_c>= num_c:\n",
    "                break\n",
    "        \n",
    "    return df_copy\n",
    "            \n",
    "def LocalPreferentialSampling(df,expl,numerical=['priors_count']):\n",
    "    df_copy = df.copy()\n",
    "    index_to_drop_a,index_to_add_a=[],[]\n",
    "    index_to_drop_c,index_to_add_c=[],[]\n",
    "    for attr in np.unique(df[expl]):\n",
    "        X_df = df[df[expl]==attr]\n",
    "        X = OneHotEncoder(drop='if_binary',sparse=False).fit_transform(X_df.drop(['race','two_year_recid',expl]+numerical,axis=1))\n",
    "        X = np.hstack((X,X_df[numerical].to_numpy()))\n",
    "        y = OneHotEncoder(drop='if_binary',sparse=False).fit_transform(df[df[expl]==attr][['two_year_recid']])\n",
    "        np.random.seed(0)\n",
    "        if not any(y):\n",
    "            y[np.random.randint(low=0,high=len(y))]=1\n",
    "        if all(y):\n",
    "            y[np.random.randint(low=0,high=len(y))]=0\n",
    "        if len(y) == 1:\n",
    "            continue\n",
    "        clf_logistic = LogisticRegression(random_state=0,max_iter=1000).fit(X, y.flatten())\n",
    "        y_prob  = clf_logistic.predict_log_proba(X) \n",
    "        \n",
    "        num_a= delta(X_df,'African-American')\n",
    "        num_c = delta(X_df,'Caucasian')\n",
    "        positive_index_sorted = np.argsort(y_prob[:,1])[np.sort(y_prob[:,1])>np.log(0.5)]\n",
    "        negative_index_sorted = np.argsort(y_prob[:,1])[np.sort(y_prob[:,1])<np.log(0.5)]\n",
    "        count_drop_a,count_add_a,count_drop_c,count_add_c = 0,0,0,0    \n",
    "\n",
    "        for index in positive_index_sorted:\n",
    "            if (df_copy.at[X_df.index[index],'race'] == 'African-American') & (count_drop_a < 0.5*num_a):\n",
    "                index_to_drop_a.append(X_df.index[index])\n",
    "                count_drop_a += 1           \n",
    "            if (df_copy.at[X_df.index[index],'race'] == 'Caucasian') & (count_add_c < 0.5*num_c):\n",
    "                index_to_add_c.append(X_df.index[index])\n",
    "                count_add_c += 1\n",
    "            if (count_add_c>=0.5*num_c) & (count_drop_a>=0.5*num_a):\n",
    "                break\n",
    "                \n",
    "                \n",
    "        for index in reversed(negative_index_sorted):\n",
    "            if (df_copy.at[X_df.index[index],'race'] == 'African-American') & (count_add_a < 0.5*num_a):\n",
    "                index_to_add_a.append(X_df.index[index])\n",
    "                count_add_a += 1           \n",
    "            if (df_copy.at[X_df.index[index],'race'] == 'Caucasian') & (count_drop_c < 0.5*num_c):\n",
    "                index_to_drop_c.append(X_df.index[index])\n",
    "                count_drop_c += 1\n",
    "            if (count_drop_c>=0.5*num_c) & (count_add_a>=0.5*num_a):\n",
    "                break\n",
    "        \n",
    "    df_added = df.iloc[index_to_add_a+index_to_add_c]\n",
    "    df_copy = df_copy.drop(index_to_drop_a+index_to_drop_c)   \n",
    "    return pd.concat([df_copy,df_added])\n",
    "\n",
    "def fpr(true,predict):\n",
    "    return ((predict == 1) & (true == 0)).mean()\n",
    "\n",
    "def fnr(true,predict):\n",
    "    return ((predict == 0) & (true == 1)).mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-animal",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-traveler",
   "metadata": {},
   "source": [
    "#### With `race`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "spanish-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "##without race\n",
    "numerical = ['priors_count']\n",
    "# numerical = []\n",
    "enc = OneHotEncoder(drop='if_binary',sparse=False)\n",
    "X = enc.fit_transform(df_cleaned.drop(['two_year_recid']+numerical,axis=1))\n",
    "X = np.hstack((X,df_cleaned[numerical].to_numpy()))\n",
    "y = df_cleaned['two_year_recid'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "cooked-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0,max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "asian-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation accuracy is:  0.6739994725390651\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print('10-fold cross validation accuracy is: ',cross_val_score(clf, X_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "limiting-diagram",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is:  0.6717226435536294\n",
      "Test accuracy in African-American group:  0.6576576576576577\n",
      "Test accuracy in Caucasian group:  0.6929347826086957\n",
      "Test accuracy difference in two groups:  0.035277124951037964\n",
      "Test FPR:  0.13759479956663057\n",
      "Test FPR in African-American group :  0.16576576576576577\n",
      "Test FPR in Caucasian group:  0.09510869565217392\n",
      "Test FNR:  0.19068255687973998\n",
      "Test FNR in African-American group:  0.17657657657657658\n",
      "Test FNR in Caucasian group:  0.21195652173913043\n"
     ]
    }
   ],
   "source": [
    "aa_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='African-American'\n",
    "ca_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='Caucasian'\n",
    "aa_acc = (y_test_pred[aa_index] == y_test[aa_index]).mean()\n",
    "ca_acc = (y_test_pred[ca_index] == y_test[ca_index]).mean()\n",
    "print('Test accuracy is: ',clf.score(X_test,y_test))\n",
    "print('Test accuracy in African-American group: ', aa_acc)\n",
    "print('Test accuracy in Caucasian group: ',ca_acc)\n",
    "print('Test accuracy difference in two groups: ', abs(aa_acc-ca_acc))\n",
    "print('Test FPR: ',fpr(y_test,y_test_pred))\n",
    "print('Test FPR in African-American group : ',fpr(y_test[aa_index],y_test_pred[aa_index]))\n",
    "print('Test FPR in Caucasian group: ',fpr(y_test[ca_index],y_test_pred[ca_index]))\n",
    "print('Test FNR: ',fnr(y_test,y_test_pred))\n",
    "print('Test FNR in African-American group: ',fnr(y_test[aa_index],y_test_pred[aa_index]))\n",
    "print('Test FNR in Caucasian group: ',fnr(y_test[ca_index],y_test_pred[ca_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-necklace",
   "metadata": {},
   "source": [
    "#### Without `race`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "corresponding-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_Male', 'x1_18', 'x1_19', 'x1_20', 'x1_21', 'x1_22', 'x1_23',\n",
       "       'x1_24', 'x1_25', 'x1_26', 'x1_27', 'x1_28', 'x1_29', 'x1_30',\n",
       "       'x1_31', 'x1_32', 'x1_33', 'x1_34', 'x1_35', 'x1_36', 'x1_37',\n",
       "       'x1_38', 'x1_39', 'x1_40', 'x1_41', 'x1_42', 'x1_43', 'x1_44',\n",
       "       'x1_45', 'x1_46', 'x1_47', 'x1_48', 'x1_49', 'x1_50', 'x1_51',\n",
       "       'x1_52', 'x1_53', 'x1_54', 'x1_55', 'x1_56', 'x1_57', 'x1_58',\n",
       "       'x1_59', 'x1_60', 'x1_61', 'x1_62', 'x1_63', 'x1_64', 'x1_65',\n",
       "       'x1_66', 'x1_67', 'x1_68', 'x1_69', 'x1_70', 'x1_71', 'x1_72',\n",
       "       'x1_73', 'x1_74', 'x1_75', 'x1_77', 'x1_78', 'x1_79', 'x1_80',\n",
       "       'x1_83', 'x2_Caucasian', 'x3_M'], dtype=object)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "central-grounds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0,max_iter=1000)\n",
    "X_train_no_race = X_train[:,[i for i in range(X_train.shape[1]) if i !=4]]\n",
    "X_test_no_race = X_test[:,[i for i in range(X_test.shape[1]) if i !=4]]\n",
    "clf.fit(X_train_no_race, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "floppy-citation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation accuracy is:  0.6671157410459843\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test_no_race)\n",
    "print('10-fold cross validation accuracy is: ',cross_val_score(clf, X_train_no_race, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "beneficial-choice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is:  0.6663055254604551\n",
      "Test accuracy in African-American group:  0.6558558558558558\n",
      "Test accuracy in Caucasian group:  0.6820652173913043\n",
      "Test accuracy difference in two groups:  0.026209361535448505\n",
      "Test FPR:  0.13109425785482123\n",
      "Test FPR in African-American group :  0.15855855855855855\n",
      "Test FPR in Caucasian group:  0.08967391304347826\n",
      "Test FNR:  0.20260021668472372\n",
      "Test FNR in African-American group:  0.18558558558558558\n",
      "Test FNR in Caucasian group:  0.22826086956521738\n"
     ]
    }
   ],
   "source": [
    "aa_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='African-American'\n",
    "ca_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='Caucasian'\n",
    "aa_acc = (y_test_pred[aa_index] == y_test[aa_index]).mean()\n",
    "ca_acc = (y_test_pred[ca_index] == y_test[ca_index]).mean()\n",
    "print('Test accuracy is: ',clf.score(X_test_no_race,y_test))\n",
    "print('Test accuracy in African-American group: ', aa_acc)\n",
    "print('Test accuracy in Caucasian group: ',ca_acc)\n",
    "print('Test accuracy difference in two groups: ', abs(aa_acc-ca_acc))\n",
    "print('Test FPR: ',fpr(y_test,y_test_pred))\n",
    "print('Test FPR in African-American group : ',fpr(y_test[aa_index],y_test_pred[aa_index]))\n",
    "print('Test FPR in Caucasian group: ',fpr(y_test[ca_index],y_test_pred[ca_index]))\n",
    "print('Test FNR: ',fnr(y_test,y_test_pred))\n",
    "print('Test FNR in African-American group: ',fnr(y_test[aa_index],y_test_pred[aa_index]))\n",
    "print('Test FNR in Caucasian group: ',fnr(y_test[ca_index],y_test_pred[ca_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-azerbaijan",
   "metadata": {},
   "source": [
    "## Local Massaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "animated-accounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5227, 67) (5227,) (923, 67) (923,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df_cleaned, test_size=0.15, random_state=0)\n",
    "train.index = range(0,len(train))\n",
    "test.index = range(0,len(test))\n",
    "df_massaged = LocalMassaging(train,'age',numerical=['priors_count'])\n",
    "numerical = ['priors_count']\n",
    "enc = OneHotEncoder(drop='if_binary',sparse=False).fit(df_cleaned.drop(['two_year_recid']+numerical,axis=1))\n",
    "X_train = enc.transform(df_massaged.drop(['two_year_recid']+numerical,axis=1))\n",
    "X_train = np.hstack((X_train,df_massaged[numerical].to_numpy()))\n",
    "y_train = df_massaged['two_year_recid'].to_numpy()\n",
    "\n",
    "X_test = enc.transform(test.drop(['two_year_recid']+numerical,axis=1))\n",
    "X_test = np.hstack((X_test,test[numerical].to_numpy()))\n",
    "y_test = test['two_year_recid'].to_numpy()\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "silent-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(random_state=0),\n",
       "             param_grid={'C': (0.5, 0.75, 1),\n",
       "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=0)\n",
    "parameters = {'C':(0.5,0.75,1), \n",
    "              'kernel':('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "clf = GridSearchCV(svc, parameters,cv=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "excess-scanner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "swedish-imagination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation accuracy is:  0.6483740284096321\n"
     ]
    }
   ],
   "source": [
    "best_clf = SVC(random_state=0,C=0.5,kernel='linear')\n",
    "best_clf.fit(X_train,y_train)\n",
    "y_test_pred = best_clf.predict(X_test)\n",
    "print('10-fold cross validation accuracy is: ',cross_val_score(best_clf, X_train_no_race, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "solved-pepper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is:  0.6576381365113759\n",
      "Test accuracy in African-American group:  0.6522522522522523\n",
      "Test accuracy in Caucasian group:  0.6657608695652174\n",
      "Test accuracy difference in two groups:  0.013508617312965154\n",
      "Test FPR:  0.12892741061755147\n",
      "Test FPR in African-American group :  0.14054054054054055\n",
      "Test FPR in Caucasian group:  0.11141304347826086\n",
      "Test FNR:  0.2134344528710726\n",
      "Test FNR in African-American group:  0.2072072072072072\n",
      "Test FNR in Caucasian group:  0.22282608695652173\n"
     ]
    }
   ],
   "source": [
    "aa_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='African-American'\n",
    "ca_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='Caucasian'\n",
    "aa_acc = (y_test_pred[aa_index] == y_test[aa_index]).mean()\n",
    "ca_acc = (y_test_pred[ca_index] == y_test[ca_index]).mean()\n",
    "print('Test accuracy is: ',best_clf.score(X_test,y_test))\n",
    "print('Test accuracy in African-American group: ', aa_acc)\n",
    "print('Test accuracy in Caucasian group: ',ca_acc)\n",
    "print('Test accuracy difference in two groups: ', abs(aa_acc-ca_acc))\n",
    "print('Test FPR: ',fpr(y_test,y_test_pred))\n",
    "print('Test FPR in African-American group : ',fpr(y_test[aa_index],y_test_pred[aa_index]))\n",
    "print('Test FPR in Caucasian group: ',fpr(y_test[ca_index],y_test_pred[ca_index]))\n",
    "print('Test FNR: ',fnr(y_test,y_test_pred))\n",
    "print('Test FNR in African-American group: ',fnr(y_test[aa_index],y_test_pred[aa_index]))\n",
    "print('Test FNR in Caucasian group: ',fnr(y_test[ca_index],y_test_pred[ca_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-wagon",
   "metadata": {},
   "source": [
    "## Local Preferential Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "supported-prayer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5227, 67) (5227,) (923, 67) (923,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df_cleaned, test_size=0.15, random_state=0)\n",
    "train.index = range(0,len(train))\n",
    "test.index = range(0,len(test))\n",
    "df_massaged = LocalMassaging(train,'age',numerical=['priors_count'])\n",
    "numerical = ['priors_count']\n",
    "enc = OneHotEncoder(drop='if_binary',sparse=False).fit(df_cleaned.drop(['two_year_recid']+numerical,axis=1))\n",
    "X_train = enc.transform(df_massaged.drop(['two_year_recid']+numerical,axis=1))\n",
    "X_train = np.hstack((X_train,df_massaged[numerical].to_numpy()))\n",
    "y_train = df_massaged['two_year_recid'].to_numpy()\n",
    "\n",
    "X_test = enc.transform(test.drop(['two_year_recid']+numerical,axis=1))\n",
    "X_test = np.hstack((X_test,test[numerical].to_numpy()))\n",
    "y_test = test['two_year_recid'].to_numpy()\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "incoming-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(random_state=0),\n",
       "             param_grid={'C': (0.5, 0.75, 1),\n",
       "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=0)\n",
    "parameters = {'C':(0.5,0.75,1), \n",
    "              'kernel':('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "clf = GridSearchCV(svc, parameters,cv=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "internal-garbage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "matched-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation accuracy is:  0.650666285722658\n"
     ]
    }
   ],
   "source": [
    "best_clf = SVC(random_state=0,C=1,kernel='rbf')\n",
    "best_clf.fit(X_train,y_train)\n",
    "y_test_pred = best_clf.predict(X_test)\n",
    "print('10-fold cross validation accuracy is: ',cross_val_score(best_clf, X_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "cathedral-switch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is:  0.6489707475622969\n",
      "Test accuracy in African-American group:  0.6342342342342342\n",
      "Test accuracy in Caucasian group:  0.6711956521739131\n",
      "Test accuracy difference in two groups:  0.03696141793967889\n",
      "Test FPR:  0.12459371614301191\n",
      "Test FPR in African-American group :  0.13513513513513514\n",
      "Test FPR in Caucasian group:  0.10869565217391304\n",
      "Test FNR:  0.22643553629469124\n",
      "Test FNR in African-American group:  0.23063063063063063\n",
      "Test FNR in Caucasian group:  0.22010869565217392\n"
     ]
    }
   ],
   "source": [
    "aa_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='African-American'\n",
    "ca_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='Caucasian'\n",
    "aa_acc = (y_test_pred[aa_index] == y_test[aa_index]).mean()\n",
    "ca_acc = (y_test_pred[ca_index] == y_test[ca_index]).mean()\n",
    "print('Test accuracy is: ',best_clf.score(X_test,y_test))\n",
    "print('Test accuracy in African-American group: ', aa_acc)\n",
    "print('Test accuracy in Caucasian group: ',ca_acc)\n",
    "print('Test accuracy difference in two groups: ', abs(aa_acc-ca_acc))\n",
    "print('Test FPR: ',fpr(y_test,y_test_pred))\n",
    "print('Test FPR in African-American group : ',fpr(y_test[aa_index],y_test_pred[aa_index]))\n",
    "print('Test FPR in Caucasian group: ',fpr(y_test[ca_index],y_test_pred[ca_index]))\n",
    "print('Test FNR: ',fnr(y_test,y_test_pred))\n",
    "print('Test FNR in African-American group: ',fnr(y_test[aa_index],y_test_pred[aa_index]))\n",
    "print('Test FNR in Caucasian group: ',fnr(y_test[ca_index],y_test_pred[ca_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-theater",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
