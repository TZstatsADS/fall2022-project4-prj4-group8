{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expensive-courtesy",
   "metadata": {},
   "source": [
    "# Algorithm 6:  Handling Conditional Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "hired-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "rolled-delight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree',\n",
       "       'is_recid', 'is_violent_recid', 'type_of_assessment', 'decile_score.1',\n",
       "       'score_text', 'screening_date', 'v_type_of_assessment',\n",
       "       'v_decile_score', 'v_score_text', 'v_screening_date', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "df.columns[df.isna().any()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "communist-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['sex','age_cat','race','priors_count','c_charge_degree',\n",
    "           'is_recid','is_violent_recid','two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "declared-forestry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>Female</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex       age_cat              race  priors_count c_charge_degree  \\\n",
       "0       Male       25 - 45  African-American             0               F   \n",
       "1       Male  Less than 25  African-American             4               F   \n",
       "2       Male  Less than 25  African-American             1               F   \n",
       "3       Male       25 - 45         Caucasian            14               F   \n",
       "4     Female       25 - 45         Caucasian             0               M   \n",
       "...      ...           ...               ...           ...             ...   \n",
       "6145    Male       25 - 45  African-American             0               M   \n",
       "6146    Male  Less than 25  African-American             0               F   \n",
       "6147    Male  Less than 25  African-American             0               F   \n",
       "6148    Male  Less than 25  African-American             0               F   \n",
       "6149  Female       25 - 45  African-American             3               M   \n",
       "\n",
       "      is_recid  is_violent_recid  two_year_recid  \n",
       "0            1                 1               1  \n",
       "1            1                 0               1  \n",
       "2            0                 0               0  \n",
       "3            1                 0               1  \n",
       "4            0                 0               0  \n",
       "...        ...               ...             ...  \n",
       "6145         1                 0               1  \n",
       "6146         0                 0               0  \n",
       "6147         0                 0               0  \n",
       "6148         0                 0               0  \n",
       "6149         0                 0               0  \n",
       "\n",
       "[6150 rows x 8 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df[selected_features][(df['race']=='Caucasian') | (df['race']=='African-American')].copy()\n",
    "df_cleaned.head()\n",
    "df_cleaned.index = np.arange(0,len(df_cleaned))\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "driven-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dexpl(df,expl,out='two_year_recid'):\n",
    "    pdelta = []\n",
    "    pstar = []\n",
    "    for v in df[expl].unique():\n",
    "        pa = 0 if np.isnan((df[df['race']=='African-American'][expl] == v).mean()) else (df[df['race']=='African-American'][expl] == v).mean()\n",
    "        pc = 0 if np.isnan((df[df['race']=='Caucasian'][expl] == v).mean()) else (df[df['race']=='Caucasian'][expl] == v).mean()\n",
    "        pdelta.append(pa-pc) \n",
    "        psa = (df[(df['race']=='African-American') & (df[expl] == v)][out] == 1).mean()\n",
    "        psa = 0 if np.isnan(psa) else psa\n",
    "        psc = (df[(df['race']=='Caucasian') & (df[expl] == v)][out] == 1).mean()\n",
    "        psc = 0 if np.isnan(psc) else psc\n",
    "        pstar.append((psa+psc)/2)\n",
    "    return sum([pdelta[i]*ps for i,ps in enumerate(pstar)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "boring-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(df_i,race):\n",
    "    g_i = (df_i['race']==race).sum()\n",
    "    p_star_a = (df_i[df_i['race']=='African-American']['two_year_recid'] == 1).mean()\n",
    "    p_star_a = 0 if np.isnan(p_star_a) else p_star_a\n",
    "    p_star_c = (df_i[df_i['race']=='Caucasian']['two_year_recid'] == 1).mean()\n",
    "    p_star_c = 0 if np.isnan(p_star_c) else p_star_c\n",
    "    p_star = (p_star_a+p_star_c)/2\n",
    "    if race == 'African-American':\n",
    "        return g_i*abs(p_star_a-p_star)\n",
    "    if race == 'Caucasian':\n",
    "        return g_i*abs(p_star_c-p_star)\n",
    "    \n",
    "def LocalMassaging(df,expl,numerical=['priors_count']):\n",
    "    df_copy = df.copy()\n",
    "    for attr in np.unique(df[expl]):\n",
    "        X_df = df[df[expl]==attr]\n",
    "        X = OneHotEncoder(drop='if_binary',sparse=False).fit_transform(X_df.drop(['race','two_year_recid',expl]+numerical,axis=1))\n",
    "        \n",
    "        X = np.hstack((X,X_df[numerical].to_numpy()))\n",
    "        y = OneHotEncoder(drop='if_binary',sparse=False).fit_transform(df[df[expl]==attr][['two_year_recid']])\n",
    "        np.random.seed(0)\n",
    "        if not any(y):\n",
    "            y[np.random.randint(low=0,high=len(y))]=1\n",
    "        if all(y):\n",
    "            y[np.random.randint(low=0,high=len(y))]=0\n",
    "        if len(y) == 1:\n",
    "            continue\n",
    "        clf_logistic = LogisticRegression(random_state=0,max_iter=1000).fit(X, y.flatten())\n",
    "        y_prob  = clf_logistic.predict_log_proba(X) \n",
    "        \n",
    "        num_a = delta(X_df,'African-American')\n",
    "        num_c= delta(X_df,'Caucasian')\n",
    "        positive_index_sorted = np.argsort(y_prob[:,1])[np.sort(y_prob[:,1])>np.log(0.5)]\n",
    "        negative_index_sorted = np.argsort(y_prob[:,1])[np.sort(y_prob[:,1])<np.log(0.5)]\n",
    "        count_a,count_c = 0,0\n",
    "        \n",
    "        for index in positive_index_sorted:\n",
    "            if df_copy.at[X_df.index[index],'race']== 'African-American':\n",
    "                df_copy.at[X_df.index[index],'two_year_recid'] = 0\n",
    "                count_a += 1\n",
    "            if count_a >= num_a:\n",
    "                break\n",
    "        for index in reversed(negative_index_sorted):\n",
    "            if df_copy.at[X_df.index[index],'race']== 'Caucasian':\n",
    "                df_copy.at[X_df.index[index],'two_year_recid'] = 1\n",
    "                count_c += 1\n",
    "            if count_c>= num_c:\n",
    "                break\n",
    "        \n",
    "    return df_copy\n",
    "            \n",
    "def LocalPreferentialSampling(df,expl,numerical=['priors_count']):\n",
    "    df_copy = df.copy()\n",
    "    index_to_drop_a,index_to_add_a=[],[]\n",
    "    index_to_drop_c,index_to_add_c=[],[]\n",
    "    for attr in np.unique(df[expl]):\n",
    "        X_df = df[df[expl]==attr]\n",
    "        X = OneHotEncoder(drop='if_binary',sparse=False).fit_transform(X_df.drop(['race','two_year_recid',expl]+numerical,axis=1))\n",
    "        X = np.hstack((X,X_df[numerical].to_numpy()))\n",
    "        y = OneHotEncoder(drop='if_binary',sparse=False).fit_transform(df[df[expl]==attr][['two_year_recid']])\n",
    "        np.random.seed(0)\n",
    "        if not any(y):\n",
    "            y[np.random.randint(low=0,high=len(y))]=1\n",
    "        if all(y):\n",
    "            y[np.random.randint(low=0,high=len(y))]=0\n",
    "        if len(y) == 1:\n",
    "            continue\n",
    "        clf_logistic = LogisticRegression(random_state=0,max_iter=1000).fit(X, y.flatten())\n",
    "        y_prob  = clf_logistic.predict_log_proba(X) \n",
    "        \n",
    "        num_a= delta(X_df,'African-American')\n",
    "        num_c = delta(X_df,'Caucasian')\n",
    "        positive_index_sorted = np.argsort(y_prob[:,1])[np.sort(y_prob[:,1])>np.log(0.5)]\n",
    "        negative_index_sorted = np.argsort(y_prob[:,1])[np.sort(y_prob[:,1])<np.log(0.5)]\n",
    "        count_drop_a,count_add_a,count_drop_c,count_add_c = 0,0,0,0    \n",
    "\n",
    "        for index in positive_index_sorted:\n",
    "            if (df_copy.at[X_df.index[index],'race'] == 'African-American') & (count_drop_a < 0.5*num_a):\n",
    "                index_to_drop_a.append(X_df.index[index])\n",
    "                count_drop_a += 1           \n",
    "            if (df_copy.at[X_df.index[index],'race'] == 'Caucasian') & (count_add_c < 0.5*num_c):\n",
    "                index_to_add_c.append(X_df.index[index])\n",
    "                count_add_c += 1\n",
    "            if (count_add_c>=0.5*num_c) & (count_drop_a>=0.5*num_a):\n",
    "                break\n",
    "                \n",
    "                \n",
    "        for index in reversed(negative_index_sorted):\n",
    "            if (df_copy.at[X_df.index[index],'race'] == 'African-American') & (count_add_a < 0.5*num_a):\n",
    "                index_to_add_a.append(X_df.index[index])\n",
    "                count_add_a += 1           \n",
    "            if (df_copy.at[X_df.index[index],'race'] == 'Caucasian') & (count_drop_c < 0.5*num_c):\n",
    "                index_to_drop_c.append(X_df.index[index])\n",
    "                count_drop_c += 1\n",
    "            if (count_drop_c>=0.5*num_c) & (count_add_a>=0.5*num_a):\n",
    "                break\n",
    "        \n",
    "    df_added = df.iloc[index_to_add_a+index_to_add_c]\n",
    "    df_copy = df_copy.drop(index_to_drop_a+index_to_drop_c)   \n",
    "    return pd.concat([df_copy,df_added])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-basis",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-ultimate",
   "metadata": {},
   "source": [
    "#### With `race`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "preceding-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "##without race\n",
    "numerical = ['priors_count']\n",
    "enc = OneHotEncoder(drop='if_binary',sparse=False)\n",
    "X = enc.fit_transform(df_cleaned.drop(['two_year_recid']+numerical,axis=1))\n",
    "X = np.hstack((X,df_cleaned[numerical].to_numpy()))\n",
    "y = df_cleaned['two_year_recid'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "interstate-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "removed-rental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(random_state=0),\n",
       "             param_grid={'C': (0.5, 0.75, 1),\n",
       "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=0)\n",
    "parameters = {'C':(0.5,0.75,1), \n",
    "              'kernel':('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "clf = GridSearchCV(svc, parameters,cv=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "surprising-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "whole-brother",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation accuracy is:  0.9684380563064549\n",
      "Test accuracy is:  0.9685807150595883\n"
     ]
    }
   ],
   "source": [
    "best_clf = SVC(random_state=0,C=0.5,kernel='linear')\n",
    "best_clf.fit(X_train,y_train)\n",
    "y_test_pred = best_clf.predict(X_test)\n",
    "print('10-fold cross validation accuracy is: ',cross_val_score(best_clf, X_train, y_train, cv=10).mean())\n",
    "print('Test accuracy is: ',best_clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "durable-warning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy in African-American group:  0.963963963963964\n",
      "Test accuracy in Caucasian group:  0.9755434782608695\n",
      "Accuracy difference in two groups:  0.011579514296905513\n"
     ]
    }
   ],
   "source": [
    "aa_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='African-American'\n",
    "ca_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='Caucasian'\n",
    "aa_acc = (y_test_pred[aa_index] == y_test[aa_index]).mean()\n",
    "ca_acc = (y_test_pred[ca_index] == y_test[ca_index]).mean()\n",
    "print('Test accuracy in African-American group: ', aa_acc)\n",
    "print('Test accuracy in Caucasian group: ',ca_acc)\n",
    "print('Accuracy difference in two groups: ', abs(aa_acc-ca_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-forwarding",
   "metadata": {},
   "source": [
    "#### Without `race`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "golden-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_Male', 'x1_25 - 45', 'x1_Greater than 45', 'x1_Less than 25',\n",
       "       'x2_Caucasian', 'x3_M', 'x4_1', 'x5_1'], dtype=object)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "danish-lexington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(random_state=0),\n",
       "             param_grid={'C': (0.5, 0.75, 1),\n",
       "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=0)\n",
    "parameters = {'C':(0.5,0.75,1), \n",
    "              'kernel':('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "clf = GridSearchCV(svc, parameters,cv=10)\n",
    "clf.fit(X_train[:,[i for i in range(X_train.shape[1]) if i !=4]], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "latest-execution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "empirical-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation accuracy is:  0.9684380563064549\n",
      "Test accuracy is:  0.9685807150595883\n"
     ]
    }
   ],
   "source": [
    "best_clf = SVC(random_state=0,C=0.5,kernel='linear')\n",
    "X_train_no_race = X_train[:,[i for i in range(X_train.shape[1]) if i !=4]]\n",
    "X_test_no_race = X_test[:,[i for i in range(X_test.shape[1]) if i !=4]]\n",
    "best_clf.fit(X_train_no_race,y_train)\n",
    "y_test_pred = best_clf.predict(X_test_no_race)\n",
    "print('10-fold cross validation accuracy is: ',cross_val_score(best_clf, X_train_no_race, y_train, cv=10).mean())\n",
    "print('Test accuracy is: ',best_clf.score(X_test_no_race,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "administrative-bachelor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy in African-American group:  0.963963963963964\n",
      "Test accuracy in Caucasian group:  0.9755434782608695\n",
      "Accuracy difference in two groups:  0.011579514296905513\n"
     ]
    }
   ],
   "source": [
    "aa_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='African-American'\n",
    "ca_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='Caucasian'\n",
    "aa_acc = (y_test_pred[aa_index] == y_test[aa_index]).mean()\n",
    "ca_acc = (y_test_pred[ca_index] == y_test[ca_index]).mean()\n",
    "print('Test accuracy in African-American group: ', aa_acc)\n",
    "print('Test accuracy in Caucasian group: ',ca_acc)\n",
    "print('Accuracy difference in two groups: ', abs(aa_acc-ca_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-disability",
   "metadata": {},
   "source": [
    "## Local Massaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "olympic-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_massaged = LocalMassaging(df_cleaned,'age_cat',numerical=['priors_count'])\n",
    "numerical = ['priors_count']\n",
    "enc = OneHotEncoder(drop='if_binary',sparse=False)\n",
    "X = enc.fit_transform(df_massaged.drop(['two_year_recid']+numerical,axis=1))\n",
    "X = np.hstack((X,df_massaged[numerical].to_numpy()))\n",
    "y = df_massaged['two_year_recid'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "partial-secondary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(random_state=0),\n",
       "             param_grid={'C': (0.5, 0.75, 1),\n",
       "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=0)\n",
    "parameters = {'C':(0.5,0.75,1), \n",
    "              'kernel':('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "clf = GridSearchCV(svc, parameters,cv=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "aquatic-dynamics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "handled-opposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation accuracy is:  0.9250089741617401\n",
      "Test accuracy is:  0.9187432286023836\n"
     ]
    }
   ],
   "source": [
    "best_clf = SVC(random_state=0,C=0.5,kernel='linear')\n",
    "X_train_no_race = X_train[:,[i for i in range(X_train.shape[1]) if i !=4]]\n",
    "X_test_no_race = X_test[:,[i for i in range(X_test.shape[1]) if i !=4]]\n",
    "best_clf.fit(X_train_no_race,y_train)\n",
    "y_test_pred = best_clf.predict(X_test_no_race)\n",
    "print('10-fold cross validation accuracy is: ',cross_val_score(best_clf, X_train_no_race, y_train, cv=10).mean())\n",
    "print('Test accuracy is: ',best_clf.score(X_test_no_race,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "plain-arnold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy in African-American group:  0.9225225225225225\n",
      "Test accuracy in Caucasian group:  0.9130434782608695\n",
      "Accuracy difference in two groups:  0.009479044261653025\n"
     ]
    }
   ],
   "source": [
    "aa_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='African-American'\n",
    "ca_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='Caucasian'\n",
    "aa_acc = (y_test_pred[aa_index] == y_test[aa_index]).mean()\n",
    "ca_acc = (y_test_pred[ca_index] == y_test[ca_index]).mean()\n",
    "print('Test accuracy in African-American group: ', aa_acc)\n",
    "print('Test accuracy in Caucasian group: ',ca_acc)\n",
    "print('Accuracy difference in two groups: ', abs(aa_acc-ca_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-combining",
   "metadata": {},
   "source": [
    "## Local Preferential Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "specialized-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = LocalPreferentialSampling(df_cleaned,'age_cat',numerical=['priors_count'])\n",
    "numerical = ['priors_count']\n",
    "enc = OneHotEncoder(drop='if_binary',sparse=False)\n",
    "X = enc.fit_transform(df_resampled.drop(['two_year_recid']+numerical,axis=1))\n",
    "X = np.hstack((X,df_resampled[numerical].to_numpy()))\n",
    "y = df_resampled['two_year_recid'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "solar-compilation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(random_state=0),\n",
       "             param_grid={'C': (0.5, 0.75, 1),\n",
       "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=0)\n",
    "parameters = {'C':(0.5,0.75,1), \n",
    "              'kernel':('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "clf = GridSearchCV(svc, parameters,cv=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "editorial-monaco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation accuracy is:  0.9674761726848494\n",
      "Test accuracy is:  0.9750812567713976\n"
     ]
    }
   ],
   "source": [
    "best_clf = SVC(random_state=0,C=0.5,kernel='linear')\n",
    "X_train_no_race = X_train[:,[i for i in range(X_train.shape[1]) if i !=4]]\n",
    "X_test_no_race = X_test[:,[i for i in range(X_test.shape[1]) if i !=4]]\n",
    "best_clf.fit(X_train_no_race,y_train)\n",
    "y_test_pred = best_clf.predict(X_test_no_race)\n",
    "print('10-fold cross validation accuracy is: ',cross_val_score(best_clf, X_train_no_race, y_train, cv=10).mean())\n",
    "print('Test accuracy is: ',best_clf.score(X_test_no_race,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "abandoned-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy in African-American group:  0.9768270944741533\n",
      "Test accuracy in Caucasian group:  0.9723756906077348\n",
      "Accuracy difference in two groups:  0.004451403866418513\n"
     ]
    }
   ],
   "source": [
    "aa_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='African-American'\n",
    "ca_index = enc.inverse_transform(X_test[:,:-1])[:,2]=='Caucasian'\n",
    "aa_acc = (y_test_pred[aa_index] == y_test[aa_index]).mean()\n",
    "ca_acc = (y_test_pred[ca_index] == y_test[ca_index]).mean()\n",
    "print('Test accuracy in African-American group: ', aa_acc)\n",
    "print('Test accuracy in Caucasian group: ',ca_acc)\n",
    "print('Accuracy difference in two groups: ', abs(aa_acc-ca_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-folks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
